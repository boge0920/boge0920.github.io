<html>
  <head>
    <meta content='Junbo Zhang | SWJTU & CUHK' property='og:title' />
    <title>Junbo Zhang | SWJTU & CUHK</title>
    <!-- <subtitle>Simple, Easy, Fast</subtitle> -->
    <link href='/images/fav.png' rel='shortcut icon'>
<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css' />
<link href='/stylesheets/style.css' rel='stylesheet' type='text/css' />
<link href='/stylesheets/syntax.css' rel='stylesheet' type='text/css' />
<link href='/stylesheets/responsive.css' rel='stylesheet' type='text/css' />
<!-- - -->
<script src='/javascripts/jquery.js' type='text/javascript'></script>
<script src='/javascripts/pd.js' type='text/javascript'></script>
<script src='/javascripts/basics.js' type='text/javascript'></script>
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<!-- - -->
<meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type' />
<meta content="http://muan.co/images/og.png" property="og:image" />
<meta content="" property="fb:app_id" />

  <meta content='' property='og:url' />
  <meta content="" property='og:description' />
  <meta content="blog" property="og:type" />

<!-- - -->
<script type='text/javascript'>
  //<![CDATA[
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', '']);
    _gaq.push(['_trackPageview']);
    
    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  //]]>
</script>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=604714799556697";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

  </head>
    <header>
<!--<a id="go-back-home" href="/"><img src="/images/header.jpg" alt="scribble" width="530" height="59"></a>

<a id="go-back-home" href="/"><img src="/images/scribble.png" alt="scribble" width="53" height="59"></a>
<p>Junbo Zhang | SWJTU & CUHK</p>
-->
</header>

    <div id='container'>
      <head>
<div class="block">
  
    <a target="_top" class="main" href="/">HOME</a>
  
    <a target="_top" class="main" href="/research">RESEARCH</a>
  
    <a target="_top" class="main" href="/publications">PUBLICATIONS</a>
  
    <a target="_top" class="main" href="/awards">AWARDS</a>
  
    <a target="_top" class="main" href="/activities">ACTIVITIES</a>
  
    <a target="_top" class="main" href="/links">LINKS</a>
  
</div>
</head>

      <div class="content">
        <h2 id="deep-learning-datasets">Deep Learning: Datasets</h2>
<hr />
<h2 id="classification-datasets-results---discover-the-current-state-of-the-art-in-objects-classification."><a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html">Classification datasets results</a> - Discover the current state of the art in objects classification.</h2>
<ul>
<li><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></li>
<li><a href="http://www.cs.utoronto.ca/~kriz/cifar.html">CIFAR-10</a></li>
<li><a href="http://www.cs.utoronto.ca/~kriz/cifar.html">CIFAR-100</a></li>
<li><a href="http://www.stanford.edu/~acoates//stl10/">STL-10</a></li>
<li><a href="http://ufldl.stanford.edu/housenumbers/">SVHN</a></li>
<li>ILSVRC2012 task 1</li>
<li><a href="http://www.cs.ubc.ca/labs/beta/Projects/autoweka/datasets/">Auto-WEKA : Sample Datasets</a></li>
</ul>
<hr />
<h2 id="used">Used</h2>
<ul>
<li><h4><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">USPS</a> - zip code data.</h4>
<p><a href="http://www-i6.informatik.rwth-aachen.de/~keysers/Pubs/SPR2002/node10.html">benchmark results</a></p></li>
<li><h4><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a> - handwritten digits</h4></li>
<li><h4><a href="http://www.iro.umontreal.ca/~lisa/twiki/bin/view.cgi/Public/DeepVsShallowComparisonICML2007">MNIST variants</a></h4></li>
<li><h4><a href="http://www.cs.utoronto.ca/~kriz/cifar.html">CIFAR-10</a></h4></li>
</ul>
<hr />
<h2 id="other---cite-them-from-the-suggested-datasets-by-deep-learning-website-and-these-datasets-can-be-used-for-benchmarking-deep-learning-algorithms">Other - Cite them from the suggested <a href="http://deeplearning.net/datasets/">datasets</a> by <a href="http://deeplearning.net/">Deep Learning website</a> and these datasets can be used for benchmarking deep learning algorithms:</h2>
<h3 id="symbolic-music-datasets"><strong>Symbolic Music Datasets</strong></h3>
<hr />
<ul>
<li>Piano-midi.de: classical piano pieces (<a href="http://www.piano-midi.de/">http://www.piano-midi.de/</a>)</li>
<li>Nottingham : over 1000 folk tunes (<a href="http://abc.sourceforge.net/NMD/">http://abc.sourceforge.net/NMD/</a>)</li>
<li>MuseData: electronic library of classical music scores (<a href="http://musedata.stanford.edu/">http://musedata.stanford.edu/</a>)</li>
<li>JSB Chorales: set of four-part harmonized chorales (<a href="http://www.jsbchorales.net/index.shtml">http://www.jsbchorales.net/index.shtml</a>)</li>
</ul>
<h3 id="natural-images"><strong>Natural Images</strong></h3>
<hr />
<ul>
<li>MNIST: handwritten digits (<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>)</li>
<li>NIST: similar to MNIST, but larger</li>
<li>Perturbed NIST: a dataset developed in Yoshua’s class (NIST with tons of deformations)</li>
<li>CIFAR10 / CIFAR100: 32×32 natural image dataset with 10/100 categories ( <a href="http://www.cs.utoronto.ca/%7Ekriz/cifar.html">http://www.cs.utoronto.ca/~kriz/cifar.html</a>)</li>
<li>Caltech 101: pictures of objects belonging to 101 categories (<a href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/">http://www.vision.caltech.edu/Image_Datasets/Caltech101/</a>)</li>
<li>Caltech 256: pictures of objects belonging to 256 categories (<a href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/%29%C2%A0">http://www.vision.caltech.edu/Image_Datasets/Caltech256/) </a></li>
<li>Caltech Silhouettes: 28×28 binary images contains silhouettes of the Caltech 101 dataset</li>
<li>STL-10 dataset is an image recognition dataset for developing unsupervised feature learning, deep learning, self-taught learning algorithms. It is inspired by the <a href="http://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a> but with some modifications. <a href="http://www.stanford.edu/~acoates//stl10/">http://www.stanford.edu/~acoates//stl10/</a></li>
<li>The Street View House Numbers (SVHN) Dataset - <a href="http://ufldl.stanford.edu/housenumbers/">http://ufldl.stanford.edu/housenumbers/</a></li>
<li>NORB: binocular images of toy figurines under various illumination and pose (<a href="http://www.cs.nyu.edu/%7Eylclab/data/norb-v1.0/">http://www.cs.nyu.edu/~ylclab/data/norb-v1.0/</a>)</li>
<li>Imagenet: image database organized according to the WordNethierarchy (<a href="http://www.image-net.org/">http://www.image-net.org/</a>)</li>
<li>Pascal VOC: various object recognition challenges (<a href="http://pascallin.ecs.soton.ac.uk/challenges/VOC/">http://pascallin.ecs.soton.ac.uk/challenges/VOC/</a>)</li>
<li>Labelme: A large dataset of annotated images, <a href="http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php">http://labelme.csail.mit.edu/Release3.0/browserTools/php/dataset.php</a></li>
</ul>
<h3 id="artificial-datasets"><strong>Artificial Datasets</strong></h3>
<hr />
<ul>
<li><a href="https://github.com/caglar/Arcade-Universe">Arcade Universe</a>- An artificial dataset generator with images containing arcade games sprites such as tetris pentomino/tetromino objects. This generator is based on the O. Breleux’s <a href="https://github.com/breuleux/bugland">bugland</a> dataset generator.</li>
<li>A collection of datasets inspired by the ideas from <a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/BabyAISchool">BabyAISchool</a>:
<ul>
<li><a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/BabyAIShapesDatasets">BabyAIShapesDatasets</a> : distinguishing between 3 simple shapes</li>
<li><a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/BabyAIImageAndQuestionDatasets">BabyAIImageAndQuestionDatasets</a> : a question-image-answer dataset</li>
</ul></li>
<li>Datasets generated for the purpose of an empirical evaluation of deep architectures (<a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/DeepVsShallowComparisonICML2007">DeepVsShallowComparisonICML2007</a>):
<ul>
<li><a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/MnistVariations">MnistVariations</a> : introducing controlled variations in MNIST</li>
<li><a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/RectanglesData">RectanglesData</a> : discriminating between wide and tall rectangles</li>
<li><a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/ConvexNonConvex">ConvexNonConvex</a> : discriminating between convex and nonconvex shapes</li>
<li><a href="http://www.iro.umontreal.ca/%7Elisa/twiki/bin/view.cgi/Public/BackgroundCorrelation">BackgroundCorrelation</a> : controlling the degree of correlation in noisy MNIST backgrounds</li>
</ul></li>
</ul>
<h3 id="faces"><strong>Faces</strong></h3>
<hr />
<ul>
<li>Labelled Faces in the Wild: 13,000 images of faces collected from the web, labelled with the name of the person pictured (<a href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a>)</li>
<li>Toronto Face Dataset</li>
<li>Olivetti: a few images of several different people (<a href="http://www.cs.nyu.edu/%7Eroweis/data.html">http://www.cs.nyu.edu/~roweis/data.html</a>)</li>
<li>COIL 20: different objects imaged at every angle in a 360 rotation(<a href="http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php">http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php</a>)</li>
<li>COIL100: different objects imaged at every angle in a 360 rotation (<a href="http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php">http://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php</a>)</li>
<li>Multi-Pie: The CMU Multi-PIE Face Database (<a href="http://www.multipie.org/">http://www.multipie.org/</a>)</li>
<li>Face-in-Action (<a href="http://www.flintbox.com/public/project/5486/">http://www.flintbox.com/public/project/5486/</a>)</li>
<li>JACFEE: Japanese and Caucasian Facial Expressions of Emotion (<a href="http://www.humintell.com/jacfee/">http://www.humintell.com/jacfee/</a>)</li>
<li>FERET: The Facial Recognition Technology Database (<a href="http://www.itl.nist.gov/iad/humanid/feret/feret_master.html">http://www.itl.nist.gov/iad/humanid/feret/feret_master.html</a>)</li>
<li>mmifacedb: MMI Facial Expression Database (<a href="http://www.mmifacedb.com/">http://www.mmifacedb.com/</a>)</li>
<li>IndianFaceDatabase: <a href="http://vis-www.cs.umass.edu/%7Evidit/IndianFaceDatabase/">http://vis-www.cs.umass.edu/~vidit/IndianFaceDatabase/</a>)</li>
</ul>
<h3 id="text"><strong>Text</strong></h3>
<hr />
<ul>
<li>20 newsgroups: classification task, mapping word occurences to newsgroup ID (<a href="http://qwone.com/%7Ejason/20Newsgroups/">http://qwone.com/~jason/20Newsgroups/</a>)</li>
<li>Reuters (RCV*) Corpuses: text/topic prediction (<a href="http://about.reuters.com/researchandstandards/corpus/">http://about.reuters.com/researchandstandards/corpus/</a>)</li>
<li>Penn Treebank : used for next word prediction or next character prediction (<a href="http://www.cis.upenn.edu/%7Etreebank/">http://www.cis.upenn.edu/~treebank/</a>)</li>
<li>Broadcast News: large text dataset, classically used for next word prediction (<a href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC97S44">http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC97S44</a>)</li>
<li>Wikipedia Dataset</li>
<li>Multidomain sentiment analysis dataset: <a href="http://www.cs.jhu.edu/~mdredze/datasets/sentiment/">http://www.cs.jhu.edu/~mdredze/datasets/sentiment/</a></li>
</ul>
<h3 id="speech"><strong>Speech</strong></h3>
<hr />
<ul>
<li>TIMIT Speech Corpus: phoneme classification (<a href="http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S1">http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC93S1</a>)</li>
<li>Aurora : Timit with noise and additional information</li>
</ul>
<h3 id="recommendation-systems"><strong>Recommendation Systems</strong></h3>
<hr />
<ul>
<li>MovieLens: Two datasets available from <a href="http://www.grouplens.org/">http://www.grouplens.org</a>. The first dataset has 100,000 ratings for 1682 movies by 943 users, subdivided into five disjoint subsets. The second dataset has about 1 million ratings for 3900 movies by 6040 users. </li>
<li>Jester: This <a href="http://www.ieor.berkeley.edu/~goldberg/jester-data/">dataset</a> contains 4.1 million continuous ratings (-10.00 to +10.00) of 100 jokes from 73,421 users.</li>
<li>Netflix Prize: Netflix released an anonymised version of their movie rating <a href="http://www.netflixprize.com/">dataset</a>; it consists of 100 million ratings, done by 480,000 users who have rated between 1 and all of the 17,770 movies.</li>
<li>Book-Crossing dataset: This <a href="http://www.informatik.uni-freiburg.de/~cziegler/BX/">dataset</a> is from the Book-Crossing community, and contains 278,858 users providing 1,149,780 ratings about 271,379 books.</li>
</ul>
<h3 id="misc"><strong>Misc</strong></h3>
<hr />
<ul>
<li>“Musk” dataset</li>
<li>CMU Motion Capture Database: (<a href="http://mocap.cs.cmu.edu/">http://mocap.cs.cmu.edu/</a>)</li>
<li>Brodatz dataset: texture modeling (<a href="http://www.ux.uis.no/%7Etranden/brodatz.html">http://www.ux.uis.no/~tranden/brodatz.html</a>)</li>
<li>Million Song dataset: <a href="http://labrosa.ee.columbia.edu/millionsong/">http://labrosa.ee.columbia.edu/millionsong/</a></li>
<li>Merck Molecular Activity Challenge - <a href="http://www.kaggle.com/c/MerckActivity/data">http://www.kaggle.com/c/MerckActivity/data</a></li>
</ul>
<h3 id="graph"><strong>Graph</strong></h3>
<hr />
<ul>
<li><a href="http://snap.stanford.edu/data/web-BerkStan.html">Berkeley-Stanford web graph</a></li>
</ul>

      </div>
    </div>
    <footer>
  Copyright © 2014 - Junbo Zhang -
  Built with <a href="http://jekyllrb.com" class="muted"> Jekyll </a> using <a href="http://github.com/muan/scribble" class="muted"> Scribble </a> theme
  <br />
  <br />
  <!--
  <img src="/images/scribble2.png" alt="scribble" />
  -->
</footer>

  </body>
</html>
