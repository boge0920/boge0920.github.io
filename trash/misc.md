---
layout: index
title: Misc
---

### Machine Learning
- [Implementing a Principal Component Analysis (PCA) in Python step by step](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)
- [初识压缩感知Compressive Sensing](http://blog.csdn.net/abcjennifer/article/details/7721834)

### Website
- 表格生成器: <http://www.tablesgenerator.com/>
- [使用 GitHub, Jekyll 打造自己的免费独立博客](http://blog.csdn.net/on_1y/article/details/19259435)

### Blogs

- 52ml: <http://www.52ml.net>
- CV Blogs: <http://www.cvchina.info>
- FastML: <http://fastml.com>
- Freemind: <http://freemind.pluskid.org>
- BP推导, KL散度: <http://www.stanford.edu/class/cs294a/sparseAutoencoder.pdf>
- 别人的一些尝试, pretraining, ReLU, ...: <http://ift6266h13yangyang.wordpress.com/>

### 正则

- L2惩罚: $\lambda \sum_{ij} W_{ij}^2$
    *  $\lambda$是正则项系数，如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的`variance`较小，但是可能出现欠拟合的现象；相反，如果$\lambda$值很小，说明比较注重对训练数据的拟合，在训练数据上的`bias`会小，但是可能会导致过拟合。

